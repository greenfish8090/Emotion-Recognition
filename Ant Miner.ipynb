{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f3c9b2f",
   "metadata": {},
   "source": [
    "# An implementation of the Ant miner paper for Emotion Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87691e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_tkagg import (FigureCanvasTkAgg, \n",
    "NavigationToolbar2Tk)\n",
    "import copy\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from pandastable import Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c2f993",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Resources/Ravdess Dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783eb5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Window:\n",
    "    def __init__(self,title,geometry):\n",
    "        self.w = Tk()\n",
    "        self.w.title(title)\n",
    "        self.w.option_add('*Font','25')\n",
    "        self.w.geometry(geometry)\n",
    "        self.pframe = ttk.Frame(self.w, padding=\"12 12 12 12\")\n",
    "        self.frame = ttk.Frame(self.w, padding=\"12 12 12 12\")\n",
    "        self.progress = ttk.Frame(self.w, padding=\"12 12 12 12\")\n",
    "        self.dataframe = ttk.Frame(self.w,padding=\"12 12 12 12\")\n",
    "        self.tf  = ttk.Frame(self.w, padding=\"12 12 12 12\")\n",
    "        self.pframe.place(relx=0.1,rely=0.2)\n",
    "        self.frame.pack()\n",
    "        self.tf.place(relx=0.3725,rely=0.26146789)\n",
    "        self.dataframe.place(relx=0.8,rely=0.4)\n",
    "        self.progress.place(relx=0.75, rely=0.6)\n",
    "        \n",
    "        self.w.attributes('-fullscreen', True)\n",
    "    \n",
    "    def plabel(self, text):\n",
    "        ttk.Label(self.pframe,text=str(text),wraplength=600).pack()\n",
    "    \n",
    "    def label(self,text):\n",
    "        ttk.Label(self.frame,text=str(text),wraplength=600).pack()\n",
    "    \n",
    "    def exit_button(self,text=\"Next\"):\n",
    "        self.exit = ttk.Button(self.frame,text=text,command=self.w.destroy)\n",
    "        self.exit.pack()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912040d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# win = Window(title=\"Welcome!\",geometry=\"800x100\")\n",
    "\n",
    "# win.label(\"Welcome! This is an example of how the output will be displayed in this code.\")\n",
    "# win.exit_button()\n",
    "# win.w.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_candidate_thresholds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aeffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_thresholds = df.quantile(np.linspace(0, 1, n_candidate_thresholds))\n",
    "\n",
    "# win = Window(title=\"candidate_thresholds\",geometry='1000x800')\n",
    "# win.label(\"Following is the candidate threshold array:\")\n",
    "\n",
    "# ct_table = Table(win.tf,dataframe=candidate_thresholds,showtoolbar=True,showstatusbar=True)\n",
    "# ct_table.show()\n",
    "# win.exit_button()\n",
    "# win.w.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb42ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = df['class'].unique()\n",
    "#emotions\n",
    "\n",
    "# win = Window(title=\"List of Emotions\",geometry=\"800x100\")\n",
    "# win.label(\"These are the possible emotions in our dataset:\")\n",
    "# win.label(emotions)\n",
    "\n",
    "# win.exit_button()\n",
    "# win.w.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d752a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceaddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GE_df = pd.DataFrame(columns=cols)\n",
    "GE_df = GE_df.drop('class', axis=1)\n",
    "LT_df = GE_df.copy(deep=True)\n",
    "GE_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d14bf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "GE = np.zeros((n_candidate_thresholds, len(cols) - 1, len(emotions)))\n",
    "LT = GE.copy()\n",
    "GE.shape\n",
    "\n",
    "# win = Window(title=\"GE and LT\",geometry=\"800x150\")\n",
    "# win.label(\"GE and LT are two same-size arrays we will use to measure entropy in our dataset. GE represents greater than and LT represents Lesser Than.\")\n",
    "# win.label(GE.shape)\n",
    "\n",
    "# win.exit_button()\n",
    "# win.w.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27012ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, emotion in enumerate(emotions):\n",
    "    for i, (quantile, row) in enumerate(candidate_thresholds.iterrows()):\n",
    "        GE_df.loc[i] = df.loc[df['class'] == emotion].drop('class', axis=1).ge(candidate_thresholds.iloc[i]).sum()\n",
    "        LT_df.loc[i] = df.loc[df['class'] == emotion].drop('class', axis=1).lt(candidate_thresholds.iloc[i]).sum()\n",
    "    GE[:, :, e] = GE_df.to_numpy()\n",
    "    LT[:, :, e] = LT_df.to_numpy()\n",
    "\n",
    "# win = Window(title=\"GE and LT assignment\",geometry=\"800x100\")\n",
    "# win.label(\"This is a compute intensive step where GE_df and LT_df are assigned values to use later.\")\n",
    "\n",
    "# win.exit_button()\n",
    "# win.w.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6019853",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = np.split(df.sample(frac=1), [int(0.75*len(df))])\n",
    "train_len = len(train)\n",
    "test_len = len(test)\n",
    "total_len = train_len + test_len\n",
    "test_len, train_len, total_len\n",
    "\n",
    "# win = Window(title=\"Initial training variables\",geometry=\"800x100\")\n",
    "# win.label(\"Here we set our test_len, train_len and total_len.\")\n",
    "# win.label([test_len, train_len, total_len])\n",
    "\n",
    "# win.exit_button()\n",
    "# win.w.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d599cddb",
   "metadata": {},
   "source": [
    "# Entropy values\n",
    "H will be a matrix of size (1 x features). Computed in a vectorized way to save time (This would take like 10 mins if it was in a for loop, now it takes 10s). <br>\n",
    "Ok fine I'm looping through the 8 emotions so techhhhnically it's not fully vectorized. Anyway we're computing H only once so I took lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a6bc2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sums_GE = np.sum(GE, axis=2)\n",
    "sums_LT = np.sum(LT, axis=2)\n",
    "#sums_GE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd37cbe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "repeated_sums_GE = np.repeat(sums_GE[:, :, np.newaxis], GE.shape[2], axis=2)\n",
    "repeated_sums_LT = np.repeat(sums_LT[:, :, np.newaxis], LT.shape[2], axis=2)\n",
    "#repeated_sums_GE[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7885e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_GE = np.divide(GE, repeated_sums_GE, out=np.zeros_like(GE), where=repeated_sums_GE!=0)\n",
    "P_LT = np.divide(LT, repeated_sums_LT, out=np.zeros_like(LT), where=repeated_sums_LT!=0)\n",
    "#P_GE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680ee484",
   "metadata": {},
   "outputs": [],
   "source": [
    "logP_GE = np.log2(P_GE, out=np.zeros_like(P_GE), where=P_GE>0)\n",
    "logP_LT = np.log2(P_LT, out=np.zeros_like(P_LT), where=P_LT>0)\n",
    "#logP_GE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f9d06d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GE = -np.sum(np.multiply(P_GE, logP_GE), axis=2)\n",
    "LT = -np.sum(np.multiply(P_LT, logP_LT), axis=2)\n",
    "\n",
    "# win = Window(title=\"Entropy Calcuation\",geometry=\"800x150\")\n",
    "# win.label(\"\"\"Now we use GE and LT to calculate entropies for each entry in the dataset.\n",
    "# Essentially, GE and LT are recalculated first as P_GE = GE / ( sum(GE) along the 3rd axis). \n",
    "# Then the final value is calculated as -1 * sum( P_GE * log2(P_GE) ) along the 3rd axis.\"\"\")\n",
    "\n",
    "# win.exit_button()\n",
    "# win.w.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df47614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epv = sums_LT * LT / (sums_GE + sums_LT) + sums_GE * GE / (sums_GE + sums_LT)\n",
    "epv.shape\n",
    "\n",
    "# win = Window(title=\"EPV\",geometry=\"800x150\")\n",
    "# win.label(\"Now we calculate epv, which is defined as new LT * sum(LT) + new GE * sum(GE) over sum(GE) + sum(LT). It's shape is given here.\")\n",
    "# win.label(epv.shape)\n",
    "\n",
    "# win.exit_button()\n",
    "# win.w.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29d72c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies = np.minimum(\n",
    "                GE[np.argmin(epv, axis=0), np.array(range(len(cols) - 1))],\n",
    "                LT[np.argmin(epv, axis=0), np.array(range(len(cols) - 1))]\n",
    "            )\n",
    "#entropies\n",
    "\n",
    "# win = Window(title=\"Entropy calculation\",geometry=\"800x100\")\n",
    "# win.label(\"Finally, the entropies array is entered as the element-wise minimum of GE[argmin(epv)] and LT[argmin(epv)].\")\n",
    "\n",
    "# win.exit_button()\n",
    "# win.w.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = LT[:, :-2]\n",
    "vis = vis.reshape(65,100)\n",
    "plt.imshow(vis)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# win = Window(title=\"Colorplot showing entropy values\",geometry=\"800x600\")\n",
    "# win.label(\"Following is the colorplot of the array vis, made from LT:\")\n",
    "\n",
    "# figure = plt.figure(figsize=(5,5),dpi=100)\n",
    "# plot = figure.add_subplot(111)\n",
    "# bar = plot.imshow(vis)\n",
    "# figure.colorbar(bar)\n",
    "\n",
    "# canvas = FigureCanvasTkAgg(figure,win.tf)\n",
    "# canvas.get_tk_widget().grid()\n",
    "\n",
    "# win.exit_button()\n",
    "# win.w.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54108ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = GE[:, :-2]\n",
    "vis = vis.reshape(65,100)\n",
    "plt.imshow(vis)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# win = Window(title=\"Colorplot showing entropy values\",geometry=\"800x600\")\n",
    "# win.label(\"Following is the colorplot of the array vis, made from GE:\")\n",
    "\n",
    "# figure = plt.figure(figsize=(5,5),dpi=100)\n",
    "# plot = figure.add_subplot(111)\n",
    "# bar = plot.imshow(vis)\n",
    "# figure.colorbar(bar)\n",
    "\n",
    "# canvas = FigureCanvasTkAgg(figure,win.tf)\n",
    "# canvas.get_tk_widget().grid()\n",
    "\n",
    "# win.exit_button()\n",
    "# win.w.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448814c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = entropies[:-2]\n",
    "vis = vis.reshape(65,10)\n",
    "plt.imshow(vis)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# win = Window(title=\"Colorplot showing entropy values\",geometry=\"800x600\")\n",
    "# win.label(\"Following is the colorplot of the array vis, made from the entropies array:\")\n",
    "\n",
    "# figure = plt.figure(figsize=(3,5),dpi=100)\n",
    "# plot = figure.add_subplot(111)\n",
    "# bar = plot.imshow(vis)\n",
    "# figure.colorbar(bar)\n",
    "\n",
    "# canvas = FigureCanvasTkAgg(figure,win.tf)\n",
    "# canvas.get_tk_widget().grid()\n",
    "\n",
    "# win.exit_button()\n",
    "# win.w.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d362d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "def calc_threshold_and_operator(dataset):\n",
    "    GE_df = pd.DataFrame(columns=[dataset.columns[0]])\n",
    "    LT_df = GE_df.copy(deep=True)\n",
    "    GE = np.zeros((n_candidate_thresholds, 1, len(emotions)))\n",
    "    LT = GE.copy()\n",
    "    cands = candidate_thresholds[dataset.columns[0]]\n",
    "    \n",
    "    for e, emotion in enumerate(emotions):\n",
    "        for i, (quantile, row) in enumerate(candidate_thresholds.iterrows()):\n",
    "            GE_df.loc[i] = dataset.loc[dataset['class'] == emotion].drop('class', axis=1).ge(cands.iloc[i]).sum()\n",
    "            LT_df.loc[i] = dataset.loc[dataset['class'] == emotion].drop('class', axis=1).lt(cands.iloc[i]).sum()\n",
    "        GE[:, :, e] = GE_df.to_numpy()\n",
    "        LT[:, :, e] = LT_df.to_numpy()\n",
    "        \n",
    "    sums_GE = np.sum(GE, axis=2)\n",
    "    sums_LT = np.sum(LT, axis=2)\n",
    "    \n",
    "    repeated_sums_GE = np.repeat(sums_GE[:, :, np.newaxis], GE.shape[2], axis=2)\n",
    "    repeated_sums_LT = np.repeat(sums_LT[:, :, np.newaxis], LT.shape[2], axis=2)\n",
    "    \n",
    "    P_GE = np.divide(GE, repeated_sums_GE, out=np.zeros_like(GE), where=repeated_sums_GE!=0)\n",
    "    P_LT = np.divide(LT, repeated_sums_LT, out=np.zeros_like(LT), where=repeated_sums_LT!=0)\n",
    "    \n",
    "    logP_GE = np.log2(P_GE, out=np.zeros_like(P_GE), where=P_GE>0)\n",
    "    logP_LT = np.log2(P_LT, out=np.zeros_like(P_LT), where=P_LT>0)\n",
    "    \n",
    "    GE = -np.sum(np.multiply(P_GE, logP_GE), axis=2)\n",
    "    LT = -np.sum(np.multiply(P_LT, logP_LT), axis=2)\n",
    "    \n",
    "    epv = sums_LT * LT / (sums_GE + sums_LT) + sums_GE * GE / (sums_GE + sums_LT)\n",
    "    vbest = np.argmin(epv, axis=0)\n",
    "    \n",
    "    if GE[vbest, 0] < LT[vbest, 0]:\n",
    "        return float(cands.iloc[vbest]), '>='\n",
    "    \n",
    "    return float(cands.iloc[vbest]), '<'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62298a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop('class', axis=1).columns\n",
    "logK = np.log2(len(emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bf303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rule:\n",
    "    def __init__(self, train_set):\n",
    "        self.terms = {}\n",
    "        #{1:1, 18:1}\n",
    "        #{1:('>=', 13), 2:('<', 0.2)}\n",
    "        self.emotion = None\n",
    "        self.numerosity = 0\n",
    "        self.train_set = train_set\n",
    "        self.match_set = train_set\n",
    "    \n",
    "    def match(self, instance):\n",
    "        for key, value in instance.items():\n",
    "            if key in self.terms:\n",
    "                if self.terms[key][0] == '<' and self.terms[key][1] <= value:\n",
    "                    return False\n",
    "                elif self.terms[key][0] == '>=' and self.terms[key][1] > value:\n",
    "                    return False\n",
    "        return True\n",
    "    \n",
    "    def new_match_set(self, term):\n",
    "        if term['value'][0] == '>=':\n",
    "            return self.match_set.loc[self.match_set['f' + str(term['feature'])] >= term['value'][1]]\n",
    "        return self.match_set.loc[self.match_set['f' + str(term['feature'])] < term['value'][1]]\n",
    "    \n",
    "    def unmatch_set(self):\n",
    "        return pd.concat([self.train_set, self.match_set, self.match_set]).drop_duplicates(keep=False)\n",
    "    \n",
    "    def correct_set(self):\n",
    "        return self.match_set.loc[self.match_set['class'] == self.emotion]\n",
    "    \n",
    "    def exists(self, feature):\n",
    "        return feature in self.terms\n",
    "        \n",
    "    def addTerm(self, term, new_matches):\n",
    "        self.terms[term['feature']] = term['value']\n",
    "        self.match_set = new_matches\n",
    "        self.numerosity += 1\n",
    "        \n",
    "    def computeTerm(self, attribute):\n",
    "        pass\n",
    "        \n",
    "    def quality(self):\n",
    "        matches = self.match_set\n",
    "        unmatches = self.unmatch_set()\n",
    "        TP = len(matches.loc[matches['class'] == self.emotion])\n",
    "        FP = len(matches.loc[matches['class'] != self.emotion])\n",
    "        FN = len(unmatches.loc[unmatches['class'] == self.emotion])\n",
    "        TN = len(unmatches.loc[unmatches['class'] != self.emotion])\n",
    "        \n",
    "        sens = TP / (TP + FN)\n",
    "        spec = TN / (FP + TN)\n",
    "        \n",
    "        return sens * spec\n",
    "        \n",
    "    def prune(self):\n",
    "        print(\"In pruning\")\n",
    "        #Storing previous best rule\n",
    "        BackupTerms = self.terms.copy()\n",
    "    \n",
    "        # Keys of the terms. (features)\n",
    "        rule_keys = list(BackupTerms.copy().keys())\n",
    "        maxQuality = self.quality()\n",
    "        \n",
    "        #Rule must be atleast one term.\n",
    "        for i in range(self.numerosity,0,-1):\n",
    "            \n",
    "            #Getting all possible subsets , of length i, of the terms.\n",
    "            for subset in itertools.combinations(rule_keys,i):\n",
    "                #Converting it to a dictionary.\n",
    "                self.terms = {l: self.terms[l] for l in list(subset)}\n",
    "      \n",
    "              \n",
    "                #Comparing the qualities and storing the maximal of the two.\n",
    "                if maxQuality >= self.quality():\n",
    "                    self.terms = BackupTerms.copy()\n",
    "                \n",
    "                else:\n",
    "                    BackupTerms = self.terms.copy()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e88ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_probs(probs):\n",
    "    return probs / np.sum(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796acd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ant:\n",
    "    def __init__(self, index, train_set, n_tries, min_coverage):\n",
    "        self.index = index\n",
    "        self.rule = Rule(train_set)\n",
    "        self.n_tries = n_tries\n",
    "        self.min_coverage = min_coverage\n",
    "    \n",
    "    def traverse(self, T):\n",
    "        Eta = logK - entropies\n",
    "\n",
    "        Probs = np.multiply(Eta, T)\n",
    "        Probs = normalize_probs(Probs)\n",
    "        \n",
    "        should_continue = True\n",
    "        while(should_continue):\n",
    "            tries = self.n_tries\n",
    "            while(tries):\n",
    "                chosen = int(np.random.choice(len(Probs), 1, p=Probs))\n",
    "                v, op = calc_threshold_and_operator(self.rule.match_set[['f' + str(chosen), 'class']])\n",
    "                term = {'feature': chosen, 'value': (op, v)}\n",
    "                new_cov = self.rule.new_match_set(term)\n",
    "                if len(new_cov) >= self.min_coverage:\n",
    "                    self.rule.addTerm(term, new_cov)\n",
    "                    print(\"Added \" + str(term))\n",
    "                    \n",
    "                    Probs[term['feature']] = 0\n",
    "                    Probs = normalize_probs(Probs)\n",
    "                    \n",
    "                    should_continue = True\n",
    "                    break\n",
    "                tries -= 1\n",
    "                should_continue = False\n",
    "                \n",
    "    def set_emotion(self):\n",
    "        matches = self.rule.match_set\n",
    "        self.rule.emotion = matches['class'].mode()[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d4fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class World:\n",
    "    def __init__(\n",
    "        self,\n",
    "        min_coverage = 10,\n",
    "        max_uncovered = 10,\n",
    "        n_ants = 500,\n",
    "        max_dups = 1,\n",
    "        tries = 10,\n",
    "        pruning = False,\n",
    "        train_set = train.copy(deep=True),\n",
    "    ):\n",
    "    \n",
    "        self.min_coverage = min_coverage\n",
    "        self.max_uncovered = max_uncovered\n",
    "        self.n_ants = n_ants\n",
    "        self.max_dups = max_dups\n",
    "        self.tries = tries\n",
    "        self.pruning = pruning\n",
    "        self.train_set = train_set\n",
    "        self.pheromone_map = np.ones_like(entropies) * (1 / len(features))\n",
    "        self.discovered_rule_list = []\n",
    "        self.correct_covered = 0\n",
    "        \n",
    "    def reset_pheromones(self):\n",
    "        self.pheromone_map = np.ones_like(entropies) * (1 / len(features))\n",
    "\n",
    "    def deposit_pheromones(self, new_pheromones):\n",
    "        self.pheromone_map = self.pheromone_map + new_pheromones\n",
    "        \n",
    "    def evaporate_pheromones(self):\n",
    "        self.pheromone_map = self.pheromone_map / np.sum(self.pheromone_map)\n",
    "        \n",
    "    def plot_pheromones(self, a):\n",
    "        vis = self.pheromone_map[:-1]\n",
    "        vis = vis.reshape(31,21)\n",
    "        plt.imshow(vis)\n",
    "        plt.colorbar()\n",
    "        plt.savefig('Plots/Generation' + str(len(self.discovered_rule_list)) + 'ant' + str(a))\n",
    "        plt.clf()\n",
    "        \n",
    "        for widget in win.tf.winfo_children():\n",
    "            widget.destroy()\n",
    "        for widget in win.dataframe.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "        figure = plt.figure(figsize=(5,5),dpi=100)\n",
    "        plot = figure.add_subplot(111)\n",
    "        bar = plot.imshow(vis)\n",
    "        figure.colorbar(bar)\n",
    "\n",
    "        canvas = FigureCanvasTkAgg(figure,win.tf)\n",
    "        canvas.get_tk_widget().grid()\n",
    "        \n",
    "        ttk.Label(win.dataframe,text=str(\"Current generation: \"+str(len(self.discovered_rule_list)+1))).pack()\n",
    "        ttk.Label(win.dataframe,text=str(\"Current ant number: \"+str(a+1))).pack()\n",
    "\n",
    "        win.w.update()\n",
    "    \n",
    "    def dispatch_ants(self):\n",
    "        prev_rules = []\n",
    "        prev_qualities = []\n",
    "        dups = 0\n",
    "        for a in range(self.n_ants):\n",
    "            ant = Ant(a, self.train_set, self.tries, self.min_coverage)\n",
    "            print(\"initialized ant \" + str(a))\n",
    "            ant.traverse(self.pheromone_map)\n",
    "            ant.set_emotion()\n",
    "            if self.pruning:\n",
    "                ant.rule.prune()\n",
    "            \n",
    "            for prev_rule in prev_rules:\n",
    "                if ant.rule == prev_rule:\n",
    "                    dups += 1\n",
    "                    break\n",
    "            else:\n",
    "                Q = ant.rule.quality()\n",
    "\n",
    "                mask = np.zeros_like(entropies)\n",
    "                mask[list(ant.rule.terms)] = 1\n",
    "                \n",
    "                self.deposit_pheromones(np.multiply(self.pheromone_map, mask) * Q)\n",
    "                self.evaporate_pheromones()\n",
    "\n",
    "                #if a%20 == 0:\n",
    "                self.plot_pheromones(a)\n",
    "\n",
    "                prev_rules.append(ant.rule)\n",
    "                prev_qualities.append(Q)\n",
    "                \n",
    "            if dups > self.max_dups:\n",
    "                break\n",
    "\n",
    "        imax = np.argmax(prev_qualities)\n",
    "        \n",
    "        return prev_rules[imax]\n",
    "    \n",
    "    def discover_rules(self):\n",
    "        while(len(self.train_set) > self.max_uncovered):\n",
    "            self.reset_pheromones()\n",
    "            \n",
    "            for widget in win.progress.winfo_children():\n",
    "                widget.destroy()\n",
    "            ttk.Label(win.progress, text=str(\"No. of training instances: \" + str(len(train)))).pack()\n",
    "            ttk.Label(win.progress, text=str(\"No. of correctly covered instances: \" + str(self.correct_covered))).pack()\n",
    "            win.w.update()\n",
    "                \n",
    "            best_rule = self.dispatch_ants()\n",
    "            self.discovered_rule_list.append(best_rule)\n",
    "\n",
    "            corrects = best_rule.correct_set()\n",
    "            self.correct_covered += len(corrects)\n",
    "            \n",
    "            self.train_set = pd.concat([self.train_set, corrects, corrects]).drop_duplicates(keep=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc338b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Worldgen(*args):\n",
    "    a = min_coverage.get()\n",
    "    b = max_uncovered.get()\n",
    "    c = n_ants.get()\n",
    "    d = max_dups.get()\n",
    "    e = chance_murder_ant.get()\n",
    "    f = pruning.get()\n",
    "    world = World(min_coverage=a,max_uncovered=b,n_ants=c,max_dups=d,tries=e, pruning=f)\n",
    "    world.discover_rules()\n",
    "    run.destroy()\n",
    "    win.exit_button()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8964ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "win = Window(title=\"Algorithm run\",geometry=\"800x1000\")\n",
    "win.plabel(\"Now we run the actual program. Enter the required hyperparameters below:\")\n",
    "\n",
    "min_coverage = IntVar(value=10)\n",
    "win.plabel(\"\\nmin_coverage:\")\n",
    "ttk.Entry(win.pframe,width=7,textvariable=min_coverage).pack()\n",
    "max_uncovered = IntVar(value=10)\n",
    "win.plabel(\"\\nmax_uncovered:\")\n",
    "ttk.Entry(win.pframe,width=7,textvariable=max_uncovered).pack()\n",
    "n_ants = IntVar(value=500)\n",
    "win.plabel(\"\\nn_ants:\")\n",
    "ttk.Entry(win.pframe,width=7,textvariable=n_ants).pack()\n",
    "max_dups = IntVar(value=1)\n",
    "win.plabel(\"\\nmax_dups:\")\n",
    "ttk.Entry(win.pframe,width=7,textvariable=max_dups).pack()\n",
    "chance_murder_ant = IntVar(value=10)\n",
    "win.plabel(\"\\nNumber of tries for each ant:\")\n",
    "ttk.Entry(win.pframe,width=7,textvariable=chance_murder_ant).pack()\n",
    "pruning = BooleanVar(value=False)\n",
    "win.plabel(\"\\nPruning?\")\n",
    "ttk.Entry(win.pframe,width=7,textvariable=pruning).pack()\n",
    "\n",
    "run = ttk.Button(text=\"Run\",command=Worldgen)\n",
    "run.pack()\n",
    "\n",
    "\n",
    "win.w.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc5f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc42c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(row):\n",
    "    matching_rules = []\n",
    "    instance = dict(row)\n",
    "    \n",
    "    preddict = defaultdict(lambda: 0)\n",
    "    for rule in world.discovered_rule_list:\n",
    "        if rule.match(instance):\n",
    "            preddict[rule.emotion] += 1\n",
    "            \n",
    "    if preddict:\n",
    "        return max(preddict, key=preddict.get)\n",
    "    return 'unable to predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6820c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc2 = test.copy(deep=True)\n",
    "disc2.columns = range(len(df.columns))\n",
    "disc2.rename(columns={652: 'class'}, inplace=True)\n",
    "disc2['preds'] = 'nothing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2806d7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(disc2.iterrows()):\n",
    "    disc2.at[i, 'preds'] = predict(disc2.drop(['preds', 'class'], axis=1).iloc[i])\n",
    "#disc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246063e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = disc2.loc[disc2['class'] == disc2['preds']]\n",
    "predicted = disc2.loc[disc2['preds'] != 'unable to predict']\n",
    "len(correct), len(predicted), len(correct)/len(predicted), len(correct)/len(disc2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
